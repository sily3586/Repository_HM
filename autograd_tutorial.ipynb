{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "autograd_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sily3586/Repository_HM/blob/master/autograd_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx_BwqBTJzqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDHU3TyFJzqZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Autograd: 자동 미분\n",
        "===================================\n",
        "\n",
        "Pytorch에서 모든 neural network의 중심은 \"autograd\"패키지라고 할 수 있다. 일단 간단한 예시로 이를 확인해보고 우리의 첫번째 neural network를 훈련시켜보자.\n",
        "\n",
        "\"autograd\"패키지는 모든 텐서 연산에 대해 자동미분을 제공한다. 이것은 define-by-run 프레임워크로 돌아간다. define-by-work프레임워크란 역전파(backprop)가 코드의 실행에 따라 정의되는 것을 의미한다. 그리고 이러한 프레임워크에서 모든 개별 반복은 달라진다.\n",
        "\n",
        "몇가지 예시와 함께 더 간단한 용어로 살펴보자.\n",
        "\n",
        "Tensor(텐서)\n",
        "--------\n",
        "\n",
        "torch.Tensor는 패키지에서 가장 중심이되는 클래스다. torch.Tensor의 .requires_grad 속성을 True로 설정하면, 모든 연산에 대해여 추적을 시작한다. 계산이 끝나고 .backward()를 호출하면, 모든 그라디언트(gradient)를 자동으로 계산해준다. 이 텐서의 그라디언트는 .grad 속성에 누적된다.\n",
        "\n",
        ".detach()를 호출하면, 텐서 추적을 중단하고, 이후에 일어나는 계산을 추적, 누적시키지 않는다.\n",
        "\n",
        "기록을 추정하거나 메모리 사용을 예방하려면, 코드블럭을 with torch.no_grad(): 로 래핑. 이는 모델을 평가할 때 특히 도움이된다. 왜냐하면 모델이 학습가능한 파라미터 (requires_grad=True인)를 가지고 있을 수 있지만, 우리는 이 그라디언트가 필요하지 않기 때문이다.\n",
        "\n",
        "*역전파가 자동으로 계산되기 때문에 학습이 끝난 뒤, 모델을 평가할 때 .detach()를 사용하거나 torch.no_grad()를 사용하여, 그라디언트 값이 변하지 않도록 해야한다는 말 같다.\n",
        "\n",
        "자동미분을 위해 매우 중요한 클래스가 하나 더 있는데, 바로 Function 이다.\n",
        "\n",
        "Tensor와 Function은 상호연결되어 있으며, 계산 기록 전체를 인코딩하는 비순환 그래프를 생성한다. 각각의 텐서는 텐서를 생성한 Function을 참조하는 .grad_fn 속성을 가지고 있다. (단, 사용자가 생성한 텐서는 grad_fn이 없다.)\n",
        "\n",
        "도함수를 계산하고 싶으면 텐서의 .backward()를 호출하면 된다. 텐서가 스칼라값이면 (요소가 1개인 경우) backward()에 별다른 파라미터가 필요하지 않다. 하지만 하나 이상의 요소를 가지고 있으면, 텐서의 형태와 동일한 gradient 파라미터가 필요하다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u5mMGAzJzqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up2Ak0dBJzqc",
        "colab_type": "code",
        "outputId": "076b27fe-41ef-4f50-f120-21993f826174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True) #tensor를 생성하고 requires_grad 속성을 true로 설정하여 모든 연산에 대해 추적.\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvfs48T5Jzqe",
        "colab_type": "code",
        "outputId": "d04223c9-8cf8-4c23-a1f9-b3d5d7549c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y = x + 2 #x에 대해 임의의 연산 수행 후 y에 저장.\n",
        "print(y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F54WrRQYJzqh",
        "colab_type": "code",
        "outputId": "d1f4b18e-38b2-44dc-dc50-83b1d8a9ecf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(x.grad_fn) # 이 때 x는 사용자가 직접 생성했으므로 .grad_fn 속성이 없음.\n",
        "print(y.grad_fn) # 이 때 y는 연산의 결과로 생성되었기 때문에 .grad_fn 속성을 가짐."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "<AddBackward0 object at 0x7f38c35b7748>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqqKb_1kJzqj",
        "colab_type": "code",
        "outputId": "6f8d6b9b-3001-4886-a178-fc7cebaf2d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "z = y * y * 3 #y에 대해 추가적인 연산 후 z에 저장.\n",
        "out = z.mean() #z의 평균값을 연산.\n",
        "\n",
        "print(z, out) #'z'와 'out' 역시 연산의 결과로 생성되었기 때문에 .grad_fn 속성을 가짐."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DuW0v1rJzql",
        "colab_type": "code",
        "outputId": "0541ccab-5e14-45d2-bfb4-066722e5a410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#.requires_grad( ... )는 기존 텐서의 requires_grad 플래그를 제자리에서 바꿈.(덮어 쓴다는 의미인 것 같음)\n",
        "#입력 플래그값이 주어지지 않으면 디폴트 값은 False. 즉 연산에 대해 추적하지 않음.\n",
        "a = torch.randn(2, 2) #a 행렬을 랜덤하게 생성.\n",
        "a = ((a * 3) / (a - 1)) #a에 대하여 연산한 결과를 a에 저장.\n",
        "print(a.requires_grad, a.grad_fn) #a의 .requires_grad 속성을 출력. 사용자가 생성한 텐서이므로 grad_fn속성을 갖지 않음. \n",
        "a.requires_grad_(True) #a의 .requires_grad 속성의 입력 플래그를 true로 설정.\n",
        "print(a.requires_grad) #a의 .requires_grad 속성을 출력.\n",
        "b = (a * a).sum() #a에 대하여 연산한 결과를 b에 저장.\n",
        "print(b.grad_fn) #b의 grad_fn 속성 출력."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False None\n",
            "True\n",
            "<SumBackward0 object at 0x7f38c354b4e0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWuvf2NfJzqm",
        "colab_type": "text"
      },
      "source": [
        "Gradients(그래디언트)\n",
        "---------\n",
        "이제 backprop(역전파)를 해보자.\n",
        "\"out\"은 하나의 스칼라 값을 갖고있기 때문에 \"out.backward(()\"는 \"out.backward(torch.tensor(1))\"과 동일한 값을 리턴한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii1Ya4euJzqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9eUhXRsrzG69"
      },
      "source": [
        "print gradients d(out)/dx\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbA-9nq4Jzqp",
        "colab_type": "code",
        "outputId": "67cc7cb1-04b9-439d-9d25-0c168a35dca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(x.grad) #out을 x에 관하여 미분한 값 d(out)/dx 그래디언트를 출력."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMZdqhLvJzqq",
        "colab_type": "text"
      },
      "source": [
        "\"4.5\"로 이뤄진 행렬이 출력.\n",
        "\n",
        "\"out\" *Tensor*를 “$o$”라고 하면,\n",
        "\n",
        "$o = \\frac{1}{4}\\sum_i z_i$,\n",
        "\n",
        "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$이다.\n",
        "\n",
        "따라서,\n",
        "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, 이므로\n",
        "\n",
        "\n",
        "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$이다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29vM2GTfJzqq",
        "colab_type": "text"
      },
      "source": [
        "autograd를 통해 더 놀라운 것들을 할 수 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvgL4fLzJzqr",
        "colab_type": "code",
        "outputId": "783aad4b-6c13-454f-c0bc-c71c450e5d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad=True) #(3, 3)의 사이즈를 갖는 랜덤한 텐서 생성. requires_grad 속성을 true로 설정하여 연산 추적.\n",
        "\n",
        "y = x * 2 #x에 대하여 연산한 결과를 y에 저장.\n",
        "while y.data.norm() < 1000: #y 데이터의 norm이 1000보다 작으면 y에 대한 연산의 결과를 y에 저장.\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 901.9792, -578.3187,   33.0951], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtVT5s1YJzqs",
        "colab_type": "code",
        "outputId": "76efcc24-da99-49d7-cd8d-87266ec35b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float) #[0.1, 1.0, 0.0001]의 값을 가지며 데이터타입은 float인 텐서 gradients를 생성.\n",
        "y.backward(gradients) #gradients에 대하여 y.backward()연산을 수행.\n",
        "\n",
        "print(x.grad) #x의 grad를 출력"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbUqw82cJzqu",
        "colab_type": "text"
      },
      "source": [
        "\"requires_grad=true\"를 \"with torch.no_grad():\"블록으로 감싸면서 tensor의 연산 기록을 추적하는 것으로부터 자동으로 미분계수를 구하는 것을 그만둘 수도 있다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qknnPUdNJzqu",
        "colab_type": "code",
        "outputId": "72e39ae3-8fd0-4dc1-aa98-eb835e34621b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(x.requires_grad) #x에 대한 requires_grad의 설정값을 출력.\n",
        "print((x ** 2).requires_grad) #(x ** 2)에 대한 requires_grad의 설정값을 출력.\n",
        "\n",
        "with torch.no_grad():\n",
        "\tprint((x ** 2).requires_grad) #with torch.no_grad():를 통해 추적을 멈춤."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l1ueIFBJzqw",
        "colab_type": "text"
      },
      "source": [
        "**Read Later:**\n",
        "\n",
        "Documentation of ``autograd`` and ``Function`` is at\n",
        "http://pytorch.org/docs/autograd\n",
        "\n"
      ]
    }
  ]
}